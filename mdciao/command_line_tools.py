import numpy as _np

from inspect import \
    signature as _signature

from fnmatch import filter as _filter

import mdtraj as md
from matplotlib import pyplot as plt,rcParams as _rcParams

from textwrap import wrap as _twrap
from itertools import product

from os import \
    path as _path, \
    mkdir as _mkdir

from mdciao.plots import \
    compare_groups_of_contacts as _compare_groups_of_contacts

from mdciao.fragments import \
    get_fragments, _print_frag, \
    _fragments_strings_to_fragments, \
    _frag_list_2_frag_groups, \
    frag_dict_2_frag_groups as _frag_dict_2_frag_groups, \
    _rangeexpand_residues2residxs

from mdciao.nomenclature_utils import \
    LabelerCGN, LabelerBW,\
    _choose_between_consensus_dicts, \
    _guess_by_nomenclature

from mdciao.contacts import \
    select_and_report_residue_neighborhood_idxs, \
    trajs2ctcs,ContactGroup, ContactPair

from mdciao.list_utils import \
    unique_list_of_iterables_by_tuple_hashing, \
    in_what_fragment

from mdciao.site_utils import \
    sitefile2sitedict as _sitefile2sitedict, \
    sites_to_ctc_idxs as _sites_to_ctc_idxs

from mdciao.str_and_dict_utils import \
    get_sorted_trajectories as _get_sorted_trajectories, \
    _inform_about_trajectories, _tunit2tunit

from mdciao.bond_utils import \
    bonded_neighborlist_from_top

from mdciao.fragments import \
    _my_frag_colors

from mdciao.residue_and_atom_utils import \
    find_AA as _findAA


def _offer_to_create_dir(output_dir):
    r"""
    Offer to create a directory if it does not
    exist. Does nothing if it already exists

    Parameters
    ----------
    output_dir : str

    Returns
    -------

    """
    if not _path.isdir(output_dir):
        answer = input("\nThe directory '%s' does not exist. Create it on the fly [y/n]?\nDefault [y]: " % output_dir)
        if len(answer) == 0 or answer.lower().startswith("y"):
            _mkdir(output_dir)
        else:
            print("Stopping. Please check your variable 'output_dir' and try again")
            return

def _parse_consensus_option(option, consensus_type,
                            top, fragments,
                            return_Labeler=False,
                            accept_guess=False,
                            **LabelerConsensus_kwargs):
    r"""

    Frankenstein method to hide complexity away fom the command-line tools
    while making them usable at the API-level

    Internally, it instantiates a :obj:`LabelerConsensus` object to use
    its :obj:`LabelerConsensus.top2map` method
    
    A guess is performed on-the-fly using :obj:`_guess_by_nomenclature`
    to better align :obj:`top` to the :obj:`LabelerConsensus`

    Parameters
    ----------
    option : the option that was passed as argument.
        There's three usecases:
         * None, str(None)
           Nothing happens, an residx2conlab map
           full of Nones is returned
         * str
          The needed identifier to instantiate an
          :obj:`LabelerBW` or an :obj:`LabelerCGN` object.
          Examples would be a :obj:`uniprot_name` or a :obj:`ref_PDB`,
          respectively
         * :obj:`LabelerConsensus`
          An already instantiated :obj:`LabelerBW` or :obj:`LabelerCGN`
          The method then does nothing. Usecase are repeated
          calls to any of the methods in :obj:`command_line_tools`
          without each call instantiating its own :obj:`LabelerConsensus`
    consensus_type : str
        Either "CGN" or "BW"
    top : :obj:`mdtraj.Topology`
    fragments : iterable of iterables of ints
        How the :obj:`top` is fragmented. Helps
        to identify what part of :obj:`top`
        to align to the consensus sequence and produce
        the residx2conlab map
    return_Labeler : bool, default is False
        Whether to return the object itself
    accept_guess : bool, default is False
        Accept the guess generated by
        :obj:`_guess_by_nomenclature` without asking
        questions
    LabelerConsensus_kwargs : opt
        Keyword arguments of for the :obj:`LabelerConsensus`

    Returns
    -------
    map, LC

    """
    if isinstance(option, str) or option is None:
        if str(option).lower() == 'none':
            map_out = [None for __ in range(top.n_residues)]
            LC_out = None
        else:
            LC_out = {"BW": LabelerBW,
                      "CGN":LabelerCGN}[consensus_type](option, **LabelerConsensus_kwargs)

    #todo add a class check here instead of failing later on
    else:
        LC_out = option
        #print("The transformer was provided already")

    if LC_out is not None:
        answer = _guess_by_nomenclature(LC_out, top, fragments, consensus_type,
                                        return_str=False,
                                        accept_guess=accept_guess,
                                        #verbose=True
                                        )
        restrict_to_residxs = _np.hstack([fragments[ii] for ii in answer])
        map_out = LC_out.top2map(top,
                                 restrict_to_residxs=restrict_to_residxs,
                                 fill_gaps=True,
                             #    verbose=True,
                                 )
    if not return_Labeler:
        return map_out
    else:
        return map_out, LC_out

#TODO test
#TODO document
def _parse_consensus_options_and_return_fragment_defs(option_dict, top,
                                                      fragments_as_residue_idxs,
                                                      accept_guess=False,
                                                      write_to_disk_BW=False):
    fragment_defs, consensus_maps = {}, []
    for key, option in option_dict.items():
        map_CL, CL = _parse_consensus_option(option, key, top, fragments_as_residue_idxs,
                                           return_Labeler=True,
                                           accept_guess=accept_guess,
                                           write_to_disk={"BW":write_to_disk_BW,
                                                          "CGN":False}[key])
        consensus_maps.append(map_CL)
        if CL is not None:
            print("INFO: these are the %s fragments mapped onto your topology")
            fragment_defs.update(CL.top2defs(top,
                                               map_conlab=map_CL,
                                               fragments=fragments_as_residue_idxs,
                                               return_defs=True))
            if not accept_guess:
                input("Hit enter to continue!\n")

    return fragment_defs, consensus_maps

def _parse_fragment_naming_options(fragment_names, fragments, top):
    r"""
    Helper method for the CLTs to understand what/how the user wants
    the fragments to be named
    Parameters
    ----------
    fragment_names : str
        comes directly from the command line option --fragment_names,
        see :obj:`parsers._parser_add_fragment_names. Can be different
        things:
        * "" : fragment names will be named frag0,frag1,frag2 ... as needed
        * "None","none": fragment names will be None
        * comma-separated values, with as many values
        as fragments are in :obj:`fragments:
    fragments: list
        existing fragment definitions (iterables of residue indices)
         to apply the :obj:`fragment_names` to.
         Typically, :obj:`fragments` come from a call to :obj:`get_fragments`
    top : :obj:`mdtraj.Topology` (unused)
        Topolgy associated with the fragments, only used
        in the very special case where the user passed the str
        'danger'  in the command line tool. This is an advandced feature
        and will be deprecated or refactored soon. It was dangerous
        because the input :obj:`fragments` would be overwritten.
        Raises NotImplementedError ATM

    Returns
    -------
    fragment_names : list of strings

    fragments : list of fragments (only case "danger" was used, deprecated
    """
    #TODO fragment naming should be handled at the object level?

    if fragment_names == '':
        fragment_names = ['frag%u' % ii for ii in range(len(fragments))]
    elif fragment_names.lower()=="none":
        fragment_names = [None for __ in fragments]
    else:
        assert isinstance(fragment_names, str), "Argument --names invalid: %s" % fragment_names
        if 'danger' not in fragment_names.lower():
            fragment_names = [ff.strip(" ") for ff in fragment_names.split(",")]
            assert len(fragment_names) == len(
                fragments), "Mismatch between nr. fragments and fragment names %s vs %s (%s)" % (
                len(fragments), len(fragment_names), fragment_names)
            return fragment_names

        elif 'danger' in fragment_names.lower():
            raise NotImplementedError
            """
            fragments, names = dangerously_auto_fragments(top,
                                                                   method="bonds",
                                                                   verbose=False,
                                                                   force_resSeq_breaks=True,
                                                                   frag_breaker_to_pick_idx=0,
                                                                   )
            fragment_na     mes.extend(top.residue(ifrag[0]).name for ifrag in fragments[len(names):])

            for ifrag_idx, (ifrag, frag_name) in enumerate(zip(fragments, names)):
                _print_frag(ifrag_idx, top, ifrag, end='')
                print(" ", frag_name)
            return fragment_names, fragments
            """

    return fragment_names

def _parse_coloring_options(color_option, n,
                            default_color="blue",
                            color_cycle=_my_frag_colors
                            ):
    r"""
    Helper function to parse user input and return a color list

    Parameters
    ----------
    color_option: str, list, bool, or None
       * str : return a list of len n with this color as each entry
       * list : assert len(list)>=len(n) and return it the first n-entries of it
       * bool : True  : create a list of len n that repeats :obj:`color_cycle`
                        as needed
       * bool : False : create a list of len n with :obj:`default_color` as entries
                        (same as :obj:`color_option` had equal to :obj:`default_color`)
       * None : same as false
    n : int
        Wanted number of colors
    default_color: str
        Any color matplotlib understands
    color_cycle: iterable of matplotlib colors

    Returns
    -------
    colors

    """
    assert isinstance(color_cycle,list)

    if str(color_option).lower()=="none":
        color_option = False


    if isinstance(color_option, bool):
        if not color_option:
            colors = [default_color for __ in range(n)]
        else:
            vec_idxs = _np.mod(_np.arange(n), len(_my_frag_colors))
            colors = _np.array(color_cycle)[vec_idxs].tolist()
    elif isinstance(color_option, str):
        color_option = color_option.split(",")
        if len(color_option)==1:
            colors = [color_option[0] for __ in range(n)]
    elif isinstance(color_option,list):
        if len(color_option)>n:
            raise ValueError("Not enough input values %s for expected output of size n %u"%(color_option,n))
        else:
            colors = color_option[:n]

    return colors

'''
def density_by_sites(topology,
          trajectories,
          site_files,
          default_fragment_index=None,
          desc_out="density",
          output_dir='.',
                     stride=1,
          ):

    from subprocess import check_output as _co, STDOUT as _STDOUT, CalledProcessError

    _offer_to_create_dir(output_dir)

    # Prepare naming
    desc_out = desc_out.rstrip(".")

    # Inform about trajectories
    xtcs = sorted(trajectories)

    print("Will compute the densities for sites\n %s\nin the trajectories:\n  %s" % (
        "\n ".join(site_files),
        "\n  ".join(xtcs)))
    # Inform about fragments
    refgeom = md.load(topology)
    fragments = get_fragments(refgeom.top)

    sites = [_sitefile2sitedict(ff) for ff in site_files]

    with _TD() as tmpdirname:
        tocat=xtcs
        if stride > 1:
            tocat=[]
            for ii, ixtc in enumerate(xtcs):
                strided_file = path.join(tmpdirname,'%u.strided.%u.xtc'%(ii,stride))
                tocat.append(strided_file)
                cmd = "gmx trjconv -f %s -o %s -skip %u"%(ixtc, strided_file,stride)
                # OMG SUPER DANGEROUS
                try:
                    _co(cmd.split())
                except:
                    pass
        trjcatted_tmp='trjcatted.xtc'
        trjcatted_tmp=path.join(tmpdirname,trjcatted_tmp)
        cmd = "gmx trjcat -f %s -o %s -cat"%(' '.join(tocat),trjcatted_tmp)
        _co(cmd.split())

        for ss in sites:
            #print(ss["name"])
            AAresSeqs = ss["bonds"]["AAresSeq"]
            AAresSeqs = [item for sublist in AAresSeqs for item in sublist]
            #AAresSeqs = [item for sublist in AAresSeqs for item in sublist]

            resSeq2residxs, _ = _interactive_fragment_picker_by_AAresSeq(AAresSeqs, fragments, refgeom.top,
                                                                     default_fragment_idx=default_fragment_index,
                                                                     )

            aa_in_sites = _np.unique(_np.hstack([[aa.index for aa in refgeom.top.residue(ii).atoms] for ii in resSeq2residxs.values()]))
            aa_in_sites_gmx = aa_in_sites+1
            atom_in_sites_gmx_str=','.join([str(ii) for ii in aa_in_sites_gmx])
            if False:
                for ixtc in xtcs:
                    outfile = '%s.site.%s'%(splitext(ixtc)[0],ss["name"])
                    outfile = path.join(output_dir,outfile)

                    cmd = "gmx_gromaps maptide -spacing .05 -f %s -s %s -mo %s -select 'atomnr %s'"%(ixtc,topology,outfile,atom_in_sites_gmx_str)
                    print(cmd)
                    out = _co(_cmdstr2cmdtuple(cmd))#, stderr=_STDOUT)  # this should, in principle, work
                    #cmd = (gmxbin, "check", "-f", fname)

            outfile = '%s.site.%s.stride.%02u'%(desc_out.strip("."),ss["name"].strip("."),stride)
            outfile = path.join(output_dir,outfile)
            cmd = "gmx_gromaps maptide -spacing .1 -f %s -s %s -mo %s -select 'atomnr %s'"%(trjcatted_tmp,topology,outfile,atom_in_sites_gmx_str)
            print(cmd)
            out = _co(_cmdstr2cmdtuple(cmd))

def site_figures(topology,
          site_files,
                 BW_file="None",
                 CGN_PDB="None",
          ):


    print("Will print VMD lines for sites\n %s"%(
        "\n ".join(site_files)))
    # Inform about fragments
    refgeom = md.load(topology)
    fragments = get_fragments(refgeom.top)

    sites = [_sitefile2sitedict(ff) for ff in site_files]

    # Dow we want CGN definitions:

    CGN = _parse_consensus_option(CGN_PDB, 'CGN', refgeom.top, fragments)
    #for key, val in CGN.items():
    #    print(key,val)
    for ss in sites:
        #print(ss["name"])
        AAresSeqs = ss["bonds"]["AAresSeq"]
        AAresSeqs = [item for sublist in AAresSeqs for item in sublist]

        resSeq2residxs, _ = _interactive_fragment_picker_by_AAresSeq(AAresSeqs, fragments, refgeom.top)
        ctc_idxs = _sites_to_ctc_idxs_old([ss], resSeq2residxs)
        title="\nsite: %s"%ss["name"]
        if "info" in ss.keys():
            title+= ' (%s)'%ss["info"]
        print(title)
        if "best run" in ss.keys():
            vmd_cmd =  "mol new %s\n"%topology
            vmd_cmd += "mol addfile %s waitfor all\n"%(ss["best run"])
            vmd_cmd += 'mol addfile figs/density.site.%s.ccp4\n'%ss["name"]
            print(vmd_cmd[:-1])
        from .residue_and_atom_utils import shorten_AA as _shorten_AA
        for r1,r2 in ctc_idxs:
            r1 = refgeom.top.residue(r1)
            r2 = refgeom.top.residue(r2)
            print("(resname %s and resid %s or resname %s and resid %s) and noh and not name O N "%(r1.name,r1.resSeq, r2.name,r2.resSeq))
            print('%s-%s'%(_shorten_AA(r1), _shorten_AA(r2)))
            print('%s-%s'%(CGN[r1.index], CGN[r2.index]))


        input()
'''

# TODO Consider putting the figure instantiation also here
def _manage_timedep_ploting_and_saving_options(ctc_grp : ContactGroup,
                                               myfig,
                                               ctc_cutoff_Ang,
                                               output_desc,
                                               graphic_ext,
                                               output_dir=".",
                                               graphic_dpi=150,
                                               plot_timedep=True,
                                               separate_N_ctcs=False,
                                               table_ext=".dat",
                                               t_unit="ps",
                                               title=None,
                                               ):
    r"""
    CLTs share this part and have the same options to save files of timedep plots

    Parameters
    ----------
    ctc_grp
    myfig
    ctc_cutoff_Ang
    output_desc
    graphic_ext
    output_dir
    graphic_dpi
    plot_timedep
    separate_N_ctcs
    table_ext
    t_unit

    Returns
    -------

    """
    firstname = output_desc
    lastname = ""
    # TODO manage interface and sites appropiately
    if ctc_grp.is_neighborhood:
        lastname = "%s"%ctc_grp.anchor_res_and_fragment_str.replace('*', "")

    if title is None:
        title = output_desc #TODO consider using lastname

    fname_timedep = ('%s.%s.time_trace@%2.1f_Ang.%s' % (firstname,
                                                           lastname,
                                                           ctc_cutoff_Ang,
                                                           graphic_ext.strip("."))).replace("..", ".")

    fname_N_ctcs = ('%s.%s.time_trace@%2.1f_Ang.N_ctcs.%s' % (firstname,
                                                                 lastname,
                                                                 ctc_cutoff_Ang,
                                                                 graphic_ext.strip("."))).replace("..", ".")


    # Differentiate the type of figures we can have
    if len(myfig) == 1:
        if plot_timedep:
            fnames = [fname_timedep]
        else:
            fnames = [fname_N_ctcs]
    elif len(myfig) == 2:
        fnames = [fname_timedep, fname_N_ctcs]

    for iname, ifig in zip(fnames, myfig):
        fname = _path.join(output_dir, iname)
        ifig.axes[0].set_title("%s" % title) # TODO consider firstname lastname
        ifig.savefig(fname, bbox_inches="tight", dpi=graphic_dpi)
        plt.close(ifig)
        print(fname)

    if plot_timedep:
        ctc_grp.save_trajs(output_desc, table_ext, output_dir, t_unit=t_unit, verbose=True)
    if separate_N_ctcs:
        ctc_grp.save_trajs(output_desc, table_ext, output_dir, t_unit=t_unit, verbose=True,
                           ctc_cutoff_Ang=ctc_cutoff_Ang)
    print()

#TODO introduce coverage exclusion labels
# like https://coverage.readthedocs.io/en/v4.5.x/excluding.html
# or refactor these methods into another test branch
"""
def _cmdstr2cmdtuple(cmd):
    return [ii.replace("nr", "nr ") for ii in cmd.replace("atomnr ", "atomnr").replace("'", "").split()]
"""

def _my_color_schemes(istr):
    return {"peter": ["red", "purple", "gold", "darkorange"],
            "hobat": ["m", "darkgreen", "darkorange", "navy"],
            "auto":  plt.rcParams['axes.prop_cycle'].by_key()["color"]}[str(istr).lower()]

def _load_any_geom(geom):
    r"""
    Helper method for command-line-tools to create :obj:`mdtraj.Trajectories`
    from either filenames or :obj:`mdtraj.Trajectories` (i.e. do nothing)
    Parameters
    ----------
    geom : str or :obj:`mdtraj.Trajectory`

    Returns
    -------
    outgeom : :obj:`mdtraj.Trajectory`
    """
    if isinstance(geom, str):
        outgeom = md.load(geom)
    else:
        outgeom = geom

    return outgeom

def _fragment_overview(a,labtype):
    r"""
    provide the CLTs BW_overview and CGN_overview

    Parameters
    ----------
    a : :obj:`argparse.Namespace` object
        Contains the arguments used by the user
    labtype : srt, "BW" or "CGN"
        lets the code know which :obj:`LabelerConsensus` to use

    Returns
    -------
    None
    """
    if labtype == "CGN":
        val = a.PDB_code_or_txtfile
        if _path.exists(val):
            # This is sort of un-winding the loging behind
            # the initialization of LabelerCGN, but it's
            # better to add 2 lins of code here than
            # changing the object's initialization
            local_path, basename = _path.split(val)
            ref_PDB = _path.splitext(basename)[0].replace("CGN_","")
            assert len(ref_PDB)==4 and "CGN_%s.txt"%ref_PDB==basename
            obj = LabelerCGN(ref_PDB,
                             local_path=local_path,
                             #write_to_disk=a.write_to_disk
                             try_web_lookup=False)
        else:
            obj = LabelerCGN(val)

    elif labtype == "BW":
        val = a.BW_uniprot_or_file
        if _path.exists(val):
            format = "%s"
        else:
            format = _signature(LabelerBW).parameters["format"].default
        obj = LabelerBW(val,
                  format=format,
                  write_to_disk=a.write_to_disk)
    else:
        raise ValueError("Don't know the consensus type %s, only 'BW' and 'CGN'"%labtype)

    top = md.load(a.topology).top
    from .nomenclature_utils import _guess_nomenclature_fragments
    fragments = get_fragments(top,method="lig_resSeq+",
                              verbose=False)
    frag_idxs = _guess_nomenclature_fragments(obj, top, fragments)

    map_conlab = obj.top2map(top, restrict_to_residxs=_np.hstack([fragments[ii] for ii in frag_idxs]))
    obj.top2defs(top, map_conlab=map_conlab, fill_gaps=a.fill_gaps)
    if str(a.AAs).lower()!="none":
        AAs = [aa.strip(" ") for aa in a.AAs.split(",")]
        for aa in AAs:
            cands =_findAA(top,aa)
            if len(cands) == 0:
                print("No %s found in the input topology" % aa)
            else:
                for idx in cands :
                    rr = top.residue(idx)
                    print(idx, rr, map_conlab[idx])
        print()

    if str(a.labels).lower() != "none":
        labels = [aa.strip(" ") for aa in a.labels.split(",")]
        conlab2residx = obj.conlab2residx(top, map=map_conlab)
        for lab in labels:
            for match in _filter(list(conlab2residx.keys()),lab):
                idx = conlab2residx[match]
                rr = top.residue(idx)
                print(idx,rr, map_conlab[idx])

    if a.print_conlab:
        for ii, ilab in enumerate(map_conlab):
            print(ii, top.residue(ii), ilab)


def residue_neighborhoods(topology, trajectories, residues,
                          res_idxs=False,
                          ctc_cutoff_Ang=3.5,
                          stride=1,
                          n_ctcs=5,
                          n_nearest=4,
                          chunksize_in_frames=10000,
                          nlist_cutoff_Ang=15,
                          n_smooth_hw=0,
                          ask=True,
                          #TODO re-think whether ask makes sense anymore
                          sort=True,
                          pbc=True,
                          ylim_Ang=15,
                          fragments=["lig_resSeq+"],
                          fragment_names="",
                          fragment_colors=None,
                          graphic_ext=".pdf",
                          table_ext=None,
                          BW_uniprot="None",
                          CGN_PDB="None",
                          output_dir='.',
                          output_desc='neighborhood',
                          t_unit='ns',
                          curve_color="auto",
                          gray_background=False,
                          graphic_dpi=150,
                          short_AA_names=False,
                          allow_same_fragment_ctcs=True,
                          write_to_disk_BW=False,
                          plot_timedep=True,
                          n_cols=4,
                          distro=False,
                          n_jobs=1,
                          separate_N_ctcs=False,
                          ):

    # Input control residues
    if residues is None:
        print("You have to provide some residue input via the --residues option")
        return None

    _offer_to_create_dir(output_dir)

    # String comparison to allow for command line argparse-use directly
    if str(table_ext).lower() != 'none' and str(table_ext).lower().strip(".") in ["dat", "txt", "xlsx"]:
        table_ext = str(table_ext).lower().strip(".")
    else:
        table_ext = None

    # More input control
    ylim_Ang=_np.float(ylim_Ang)

    xtcs = _get_sorted_trajectories(trajectories)
    print("Will compute contact frequencies for :\n%s"
          "\n with a stride of %u frames)"%(_inform_about_trajectories(xtcs),stride))

    refgeom = _load_any_geom(topology)

    fragments_as_residue_idxs, __ = _fragments_strings_to_fragments(fragments,refgeom.top,verbose=True)
    fragment_names = _parse_fragment_naming_options(fragment_names, fragments_as_residue_idxs, refgeom.top)
    fragment_colors = _parse_coloring_options(fragment_colors,len(fragment_names))

    # Do we want BW definitions
    BWresidx2conlab = _parse_consensus_option(BW_uniprot, 'BW', refgeom.top, fragments_as_residue_idxs, write_to_disk=write_to_disk_BW)

    # Dow we want CGN definitions:
    CGNresidx2conlab = _parse_consensus_option(CGN_PDB, 'CGN', refgeom.top, fragments_as_residue_idxs)

    res_idxs_list = _rangeexpand_residues2residxs(residues, fragments_as_residue_idxs, refgeom.top,
                                                  interpret_as_res_idxs=res_idxs,
                                                  sort=sort,
                                                  pick_this_fragment_by_default=None,
                                                  additional_naming_dicts={"BW": {ii:val for ii, val in enumerate(BWresidx2conlab)},
                                                              "CGN": {ii:val for ii, val in enumerate(CGNresidx2conlab)}}
                                                  )
    print("\nWill compute neighborhoods for the residues")
    print("%s" % residues)
    print("excluding %u nearest neighbors\n" % n_nearest)

    print('%10s  %10s  %10s  %10s %10s %10s' % tuple(("residue  residx fragment  resSeq BW  CGN".split())))
    for idx in res_idxs_list:
        print('%10s  %10u  %10u %10u %10s %10s' % (refgeom.top.residue(idx), idx, in_what_fragment(idx,
                                                                                                   fragments_as_residue_idxs),
                                                   idx,
                                                   BWresidx2conlab[idx], CGNresidx2conlab[idx]))

    # Create a neighborlist
    nl = bonded_neighborlist_from_top(refgeom.top, n=n_nearest)

    # Use it to prune the contact indices
    ctc_idxs = _np.vstack(
        [[_np.sort([val, ii]) for ii in range(refgeom.top.n_residues) if ii not in nl[val] and ii != val] for val in
         res_idxs_list])

    # Can we have same-fragment contacts
    if not allow_same_fragment_ctcs:
        fragment_idxs = [[in_what_fragment(idx, fragments_as_residue_idxs) for idx in pair] for pair in ctc_idxs]
        ctc_idxs = [ctc_idxs[ii] for (ii,pair) in enumerate(fragment_idxs) if pair[0]!=pair[1]]


    print(
        "\nPre-computing likely neighborhoods by reducing the neighbor-list to %u Angstrom in the reference geom %s..." % (
            nlist_cutoff_Ang, topology), end="", flush=True)
    ctcs, ctc_idxs = md.compute_contacts(refgeom, _np.vstack(ctc_idxs), periodic=pbc)
    print("done!")

    ctc_idxs_small = _np.argwhere(ctcs[0] < nlist_cutoff_Ang / 10).squeeze()
    _, ctc_idxs_small = md.compute_contacts(refgeom, ctc_idxs[ctc_idxs_small])
    ctc_idxs_small = unique_list_of_iterables_by_tuple_hashing(ctc_idxs_small)

    print("From %u potential distances, the neighborhoods have been "
          "reduced to only %u potential contacts.\n"
          "If this number is still too high (i.e. the computation is too slow)"
          ", consider using a smaller nlist_cutoff_Ang " % (
              len(ctc_idxs), len(ctc_idxs_small)))

    ctcs_trajs, time_array, at_pair_trajs = trajs2ctcs(xtcs, refgeom.top, ctc_idxs_small, stride=stride,
                                                       chunksize=chunksize_in_frames, return_times_and_atoms=True,
                                                       consolidate=False,
                                                       n_jobs=n_jobs,
                                                       )
    print() # to make sure we don't overwrite outut
    actcs = _np.vstack(ctcs_trajs)
    ctcs_mean = _np.mean(actcs < ctc_cutoff_Ang / 10, 0)

    final_look = select_and_report_residue_neighborhood_idxs(ctcs_mean, res_idxs_list,
                                                             fragments_as_residue_idxs, ctc_idxs_small,
                                                             refgeom.top,
                                                             interactive=False,
                                                             n_ctcs=n_ctcs)

    # Create the neighborhoods as groups of contact_pair objects
    neighborhoods = {}
    empty_CGs = []
    for res_idx, val in final_look.items():
        CPs = []
        for idx in val:
            pair = ctc_idxs_small[idx]
            consensus_labels = [_choose_between_consensus_dicts(idx, [BWresidx2conlab, CGNresidx2conlab]) for idx in pair]
            fragment_idxs = [in_what_fragment(idx, fragments_as_residue_idxs) for idx in pair]
            CPs.append(ContactPair(pair,
                                   [itraj[:, idx] for itraj in ctcs_trajs],
                                   time_array,
                                   top=refgeom.top,
                                   anchor_residue_idx=res_idx,
                                   consensus_labels=consensus_labels,
                                   trajs=xtcs,
                                   fragment_idxs=fragment_idxs,
                                   fragment_names=[fragment_names[idx] for idx in fragment_idxs],
                                   fragment_colors=[fragment_colors[idx] for idx in fragment_idxs],
                                   atom_pair_trajs=[itraj[:, [idx * 2, idx * 2 + 1]] for itraj in at_pair_trajs]
                                   ))
        try:
            neighborhoods[res_idx] = ContactGroup(CPs)
        except NotImplementedError as e:
            print(e)
            empty_CGs.append(res_idx)
            neighborhoods[res_idx] = None
    if len(empty_CGs) == len(final_look):
        print("No residues have any neighbors at %2.1f Ang. No output produced." % ctc_cutoff_Ang)
        return
    elif len(empty_CGs)>0:
        print("These residues have no neighbors at %2.1f Ang"%ctc_cutoff_Ang)
        print("\n".join([str(refgeom.top.residue(ii)) for ii in empty_CGs]))

    panelheight = 3
    n_cols = _np.min((n_cols, len(res_idxs_list)))
    n_rows = _np.ceil(len(res_idxs_list) / n_cols).astype(int)
    panelsize = 4
    panelsize2font = 3.5
    bar_fig, bar_ax = plt.subplots(n_rows, n_cols,
                                     sharex=True,
                                     sharey=True,
                                     figsize=(n_cols * panelsize * 2, n_rows * panelsize), squeeze=False)

    # One loop for the histograms
    _rcParams["font.size"]=panelsize*panelsize2font
    for jax, ihood in zip(bar_ax.flatten(),
                                   neighborhoods.values()):
        if ihood is not None:
            if distro:
                ihood.plot_neighborhood_distributions(nbins=20,
                                                      jax=jax,
                                                      label_fontsize_factor=panelsize2font/panelsize,
                                                      shorten_AAs=short_AA_names,
                                                      ctc_cutoff_Ang=ctc_cutoff_Ang,
                                                      n_nearest= n_nearest
                                                      )
            else:
                ihood.plot_neighborhood_freqs(ctc_cutoff_Ang,
                                              n_nearest,
                                              jax=jax,
                                              xmax=n_ctcs,
                                              label_fontsize_factor=panelsize2font / panelsize,
                                              shorten_AAs=short_AA_names,
                                              color=ihood.partner_fragment_colors
                                              )

    if not distro:
        xmax = _np.max([jax.patches[-1].get_x()+jax.patches[-1].get_width()/2 for jax in bar_ax.flatten()
                        if len(jax.patches)>0])+.5
        [iax.set_xlim([-.5, xmax]) for iax in bar_ax.flatten()]
    bar_fig.tight_layout(h_pad=2, w_pad=0, pad=0)
    fname = "%s.overall@%2.1f_Ang.%s" % (output_desc, ctc_cutoff_Ang, graphic_ext.strip("."))
    fname = _path.join(output_dir, fname)
    bar_fig.savefig(fname, dpi=graphic_dpi)
    print("The following files have been created")
    neighborhoods = {key:val for key, val in neighborhoods.items() if val is not None}
    print(fname)
    # TDOO undecided about this
    # TODO this code is repeated in sites...can we abstract this oafa?
    if table_ext is not None:
        for ihood in neighborhoods.values():
            fname = '%s.%s@%2.1f_Ang.%s' % (output_desc,
                                            ihood.anchor_res_and_fragment_str.replace('*', ""),
                                            ctc_cutoff_Ang,
                                            table_ext)
            fname = _path.join(output_dir, fname)

            #TODO can't the frequency_spreadsheet handle this now?
            # TODO this code is repeated in sites...can we abstract this oafa?
            if table_ext=='xlsx':
                ihood.frequency_spreadsheet(ctc_cutoff_Ang, fname,
                                            write_interface=False,
                                            by_atomtypes=True,
                                            # AA_format="long",
                                            split_label="join"
                                            )
            else:
                with open(fname, 'w') as f:
                    f.write(ihood.frequency_str_ASCII_file(ctc_cutoff_Ang))
            print(fname)

    #TODO make a method out of this to use in all CLTs
    # TODO perhaps use https://github.com/python-attrs/attrs
    # to avoid boilerplate
    # Thi is very ugly
    if plot_timedep or separate_N_ctcs:
        for ihood in neighborhoods.values():
            # TODO this plot_N_ctcs and skip_timedep is very bad, but ATM my only chance without major refactor
            # TODO perhaps it would be better to burry dt in the plotting directly?
            myfig = ihood.plot_timedep_ctcs(panelheight,
                                            color_scheme=_my_color_schemes(curve_color),
                                            ctc_cutoff_Ang=ctc_cutoff_Ang,
                                            dt=_tunit2tunit["ps"][t_unit],
                                            gray_background=gray_background,
                                            n_smooth_hw=n_smooth_hw,
                                            plot_N_ctcs=True,
                                            pop_N_ctcs=separate_N_ctcs,
                                            shorten_AAs=short_AA_names,
                                            skip_timedep=not plot_timedep,
                                            t_unit=t_unit,
                                            ylim_Ang=ylim_Ang,
                                            )
            # One title for all axes on top
            title = ihood.anchor_res_and_fragment_str
            if short_AA_names:
                title = ihood.anchor_res_and_fragment_str_short
            if n_nearest >0:
                title += "\n%u nearest bonded neighbors excluded" % (n_nearest)
            _manage_timedep_ploting_and_saving_options(ihood, myfig,
                                                       ctc_cutoff_Ang,
                                                       output_desc,
                                                       graphic_ext,
                                                       output_dir=output_dir,
                                                       graphic_dpi=graphic_dpi,
                                                       plot_timedep=plot_timedep,
                                                       table_ext=table_ext,
                                                       t_unit=t_unit,
                                                       separate_N_ctcs=separate_N_ctcs,
                                                       title=title
                                                       )

    return {"ctc_idxs": ctc_idxs_small,
            'ctcs_trajs': ctcs_trajs,
            'time_array': time_array,
            "neighborhoods":neighborhoods}

def interface(
        topology=None,
        trajectories=None,
        frag_idxs_group_1=None,
        frag_idxs_group_2=None,
        BW_uniprot="None",
        CGN_PDB="None",
        chunksize_in_frames=10000,
        ctc_cutoff_Ang=3.5,
        curve_color="auto",
        fragments=['lig_resSeq+'],
        fragment_names="",
        graphic_dpi=150,
        graphic_ext=".pdf",
        gray_background=False,
        interface_cutoff_Ang=35,
        n_ctcs=10,
        n_smooth_hw=0,
        output_desc="interface",
        output_dir=".",
        short_AA_names=False,
        stride=1,
        t_unit="ns",
        plot_timedep=True,
        accept_guess=False,
        n_jobs=1,
        n_nearest=0,
        write_to_disk_BW=False,
        sort_by_av_ctcs=True,
        scheme="closest-heavy",
        separate_N_ctcs=False,
        table_ext=None,
        title=None
):

    if str(title).lower()=="none":
        title = output_desc

    output_desc = output_desc.strip(".")
    _offer_to_create_dir(output_dir)

    xtcs = _get_sorted_trajectories(trajectories)
    print("Will compute contact frequencies for :\n%s"
          "\n with a stride of %u frames)" % (_inform_about_trajectories(xtcs), stride))

    refgeom = _load_any_geom(topology)

    fragments_as_residue_idxs, user_wants_consenus = _fragments_strings_to_fragments(fragments,refgeom.top,verbose=True)
    fragment_names = _parse_fragment_naming_options(fragment_names, fragments_as_residue_idxs, refgeom.top)
    fragment_defs, \
    consensus_maps = _parse_consensus_options_and_return_fragment_defs({"BW": BW_uniprot,
                                                                        "CGN": CGN_PDB},
                                                                       refgeom.top,
                                                                       fragments_as_residue_idxs,
                                                                       accept_guess=accept_guess,
                                                                       write_to_disk_BW=write_to_disk_BW)
    if user_wants_consenus:
        intf_frags_as_residxs, \
        intf_frags_as_str_or_keys  = _frag_dict_2_frag_groups(fragment_defs, ng=2)

    else:
        intf_frags_as_residxs, \
        intf_frags_as_str_or_keys   = _frag_list_2_frag_groups(fragments_as_residue_idxs,
                                                               frag_idxs_group_1, frag_idxs_group_2,
                                                               )

    ctc_idxs = _np.vstack(list(product(intf_frags_as_residxs[0], intf_frags_as_residxs[1])))

    # Remove self-contacts
    ctc_idxs = _np.vstack([pair for pair in ctc_idxs if pair[0]!=pair[1]])

    # Create a neighborlist
    if n_nearest>0:
        print("Excluding contacts between %u nearest neighbors"%n_nearest)
        nl = bonded_neighborlist_from_top(refgeom.top, n=n_nearest)
        ctc_idxs = _np.vstack([(ii,jj) for ii,jj in ctc_idxs if jj not in nl[ii]])

    print("\nComputing distances in the interface between fragments\n%s\nand\n%s.\n"
          "The interface is defined by the residues within %3.1f "
          "Angstrom of each other in the reference topology.\n"
          "Computing interface..."
          % ('\n'.join(_twrap(', '.join(['%s' % gg for gg in intf_frags_as_str_or_keys[0]]))),
             '\n'.join(_twrap(', '.join(['%s' % gg for gg in intf_frags_as_str_or_keys[1]]))),
             interface_cutoff_Ang), end="")

    ctcs, ctc_idxs = md.compute_contacts(refgeom, _np.vstack(ctc_idxs))
    print("done!")

    ctc_idxs_receptor_Gprot = ctc_idxs[_np.argwhere(ctcs[0] < interface_cutoff_Ang / 10).squeeze()]

    interface_residx_short = [list(set(ctc_idxs_receptor_Gprot[:,0]).intersection(intf_frags_as_residxs[0])),
                              list(set(ctc_idxs_receptor_Gprot[:,1]).intersection(intf_frags_as_residxs[1]))]

    print()
    print(
        "From %u potential group_1-group_2 distances, the interface was reduced to only %u potential contacts.\nIf this "
        "number is still too high (i.e. the computation is too slow) consider using a smaller interface cutoff" % (
        len(ctc_idxs), len(ctc_idxs_receptor_Gprot)))
    print()
    ctcs, times, at_pair_trajs = trajs2ctcs(xtcs, refgeom.top, ctc_idxs_receptor_Gprot,
                                 stride=stride, return_times_and_atoms=True,
                                 consolidate=False,
                                 chunksize=chunksize_in_frames,
                                 n_jobs=n_jobs,
                                 progressbar=True,
                                 scheme=scheme
                                 )

    # Stack all data
    actcs = _np.vstack(ctcs)

    # Get frequencies so that we don't create unnecessary ctc objects
    ctcs_bin = (actcs <= ctc_cutoff_Ang / 10).astype("int").sum(0)
    ctc_frequency = ctcs_bin / actcs.shape[0]
    order = _np.argsort(ctc_frequency)[::-1]
    ctc_objs = []
    for idx in order[:n_ctcs]:
        ifreq = ctc_frequency[idx]
        if ifreq > 0:
            pair = ctc_idxs_receptor_Gprot[idx]
            #consensus_labels = [_choose_between_consensus_dicts(idx, [BW, CGN],
            #                                                    no_key=_shorten_AA(refgeom.top.residue(idx),
            #                                                                      substitute_fail=0,
            #                                                                      keep_index=True)) for idx in pair]
            consensus_labels = [_choose_between_consensus_dicts(idx, consensus_maps,
                                                                no_key=None) for idx in pair]
            fragment_idxs = [in_what_fragment(idx, fragments_as_residue_idxs) for idx in pair]
            ctc_objs.append(ContactPair(pair,
                                        [itraj[:, idx] for itraj in ctcs],
                                        times,
                                        top=refgeom.top,
                                        consensus_labels=consensus_labels,
                                        trajs=xtcs,
                                        fragment_idxs=fragment_idxs,
                                        fragment_names=[fragment_names[idx] for idx in fragment_idxs],
                                        atom_pair_trajs=[itraj[:, [idx*2, idx*2+1]] for itraj in at_pair_trajs]
                                        ))

    ctc_grp_intf = ContactGroup(ctc_objs,
                                interface_residxs=interface_residx_short)
    print()
    print(ctc_grp_intf.frequency_dataframe(ctc_cutoff_Ang).round({"freq":2, "sum":2}))
    print()
    dfs = ctc_grp_intf.frequency_sum_per_residue_names_dict(ctc_cutoff_Ang,
                                                            list_by_interface=True,
                                                            return_as_dataframe=True,
                                                            sort=sort_by_av_ctcs)
    print(dfs[0].round({"freq":2}))
    print()
    print(dfs[1].round({"freq":2}))
    panelheight = 3
    n_cols = 1
    n_rows = 2
    panelsize = 4
    panelsize2font = 3.5
    fudge = 7
    histofig, histoax = plt.subplots(n_rows, n_cols, sharex=True, sharey=False,
                                     figsize=(n_cols * panelsize * _np.ceil(ctc_grp_intf.n_ctcs/fudge),
                                              n_rows * panelsize),
                                     )

    # One loop for the histograms
    _rcParams["font.size"] = panelsize * panelsize2font
    ctc_grp_intf.plot_freqs_as_bars(ctc_cutoff_Ang,
                                    title,
                                    jax=histoax[0],
                                    xlim=_np.min((n_ctcs,ctc_grp_intf.n_ctcs)),
                                    label_fontsize_factor=panelsize2font / panelsize,
                                    shorten_AAs=short_AA_names,
                                    truncate_at=.05,
                                    )

    ctc_grp_intf.plot_frequency_sums_as_bars(ctc_cutoff_Ang,
                                             title,
                                             jax=histoax[1],
                                             list_by_interface=True,
                                             label_fontsize_factor=panelsize2font / panelsize,
                                             truncate_at=.05,
                                             sort=sort_by_av_ctcs,
                                             )
    histofig.tight_layout(h_pad=2, w_pad=0, pad=0)
    fname = "%s.overall@%2.1f_Ang.%s" % (output_desc, ctc_cutoff_Ang, graphic_ext.strip("."))
    fname = _path.join(output_dir, fname)
    histofig.savefig(fname, dpi=graphic_dpi, bbox_inches="tight")
    print("The following files have been created")
    print(fname)
    fname_excel = fname.replace(graphic_ext.strip("."),"xlsx")
    ctc_grp_intf.frequency_spreadsheet(ctc_cutoff_Ang, fname_excel, sort=sort_by_av_ctcs)
    print(fname_excel)
    fname_dat = fname.replace(graphic_ext.strip("."),"dat")
    # TODO manage filenames better, avoid overwriting here when file exists
    with open(fname_dat,"w") as f:
        f.write(ctc_grp_intf.frequency_str_ASCII_file(ctc_cutoff_Ang))
    print(fname_dat)
    if plot_timedep or separate_N_ctcs:
        myfig = ctc_grp_intf.plot_timedep_ctcs(panelheight,
                                               color_scheme=_my_color_schemes(curve_color),
                                               ctc_cutoff_Ang=ctc_cutoff_Ang,
                                               dt=_tunit2tunit["ps"][t_unit],
                                               gray_background=gray_background,
                                               n_smooth_hw=n_smooth_hw,
                                               plot_N_ctcs=True,
                                               pop_N_ctcs=separate_N_ctcs,
                                               shorten_AAs=short_AA_names,
                                               skip_timedep=not plot_timedep,
                                               t_unit=t_unit)

        _manage_timedep_ploting_and_saving_options(ctc_grp_intf, myfig,
                                                   ctc_cutoff_Ang,
                                                   output_desc,
                                                   graphic_ext,
                                                   output_dir=output_dir,
                                                   graphic_dpi=graphic_dpi,
                                                   plot_timedep=plot_timedep,
                                                   table_ext=table_ext,
                                                   t_unit=t_unit,
                                                   separate_N_ctcs=separate_N_ctcs
                                                   )

    return ctc_grp_intf

def sites(topology,
          trajectories,
          site_files,
          ctc_cutoff_Ang=3.5,
          stride=1,
          scheme="closest-heavy",
          chunksize_in_frames=10000,
          n_smooth_hw=0,
          pbc=True,
          BW_uniprot="None",
          CGN_PDB="None",
          fragments=['lig_resSeq+'],
          default_fragment_index=None,
          fragment_names="",
          output_dir='.',
          graphic_ext=".pdf",
          t_unit='ns',
          curve_color="auto",
          gray_background=False,
          graphic_dpi=150,
          short_AA_names=False,
          write_to_disk_BW=False,
          ylim_Ang=10,
          n_jobs=1,
          accept_guess=False,
          table_ext=None,
          output_desc="sites",
          ):

    ylim_Ang = _np.float(ylim_Ang)
    _offer_to_create_dir(output_dir)

    # Prepare naming
    output_desc = output_desc.rstrip(".")
    if table_ext is not None:
        table_ext = table_ext.strip(".")
    graphic_ext = graphic_ext.strip(".")
    # Inform about trajectories
    xtcs = _get_sorted_trajectories(trajectories)

    print("Will compute the sites\n %s\nin the trajectories:\n%s\n with a stride of %u frames.\n" % (
        "\n ".join(site_files),
        _inform_about_trajectories(xtcs),
          stride))

    # Inform about fragments
    refgeom = _load_any_geom(topology)

    fragments_as_residue_idxs, user_wants_consenus = _fragments_strings_to_fragments(fragments,refgeom.top,verbose=True)
    fragment_names = _parse_fragment_naming_options(fragment_names, fragments_as_residue_idxs, refgeom.top)
    fragment_defs, \
    consensus_maps = _parse_consensus_options_and_return_fragment_defs({"BW": BW_uniprot,
                                                                        "CGN": CGN_PDB},
                                                                       refgeom.top,
                                                                       fragments_as_residue_idxs,
                                                                       accept_guess=accept_guess,
                                                                       write_to_disk_BW=write_to_disk_BW)

    sites = [_sitefile2sitedict(ff) for ff in site_files]
    ctc_idxs_small, AAresSeq2residxs = _sites_to_ctc_idxs(sites, refgeom.top,
                                                          fragments=fragments_as_residue_idxs,
                                                          default_fragment_idx=default_fragment_index,
                                                          fragment_names=fragment_names)

    print('%10s  %10s  %10s  %10s %10s %10s' % tuple(("residue  residx fragment  resSeq BW  CGN".split())))
    for idx in AAresSeq2residxs.values():
        print('%10s  %10u  %10u %10u %10s %10s' % (refgeom.top.residue(idx), idx, in_what_fragment(idx,
                                                                                                   fragments_as_residue_idxs),
                                                   idx,
                                                   consensus_maps[0][idx], consensus_maps[1][idx]))

    ctcs, time_array, at_pair_trajs = trajs2ctcs(xtcs, refgeom.top, ctc_idxs_small, stride=stride,
                                       chunksize=chunksize_in_frames,
                                       return_times_and_atoms=True, consolidate=False, periodic=pbc,
                                       scheme=scheme,
                                       n_jobs=n_jobs)

    # Abstract each site to a group of contactsfragments
    site_as_gc = {}
    ctc_pairs_iterators = iter(ctc_idxs_small)
    ctc_value_idx = iter(_np.arange(len(ctc_idxs_small)))  # there has to be a better way
    for isite in sites:
        key = isite["name"]
        site_as_gc[key] = []
        for __ in range(isite["n_bonds"]):
            pair = next(ctc_pairs_iterators)
            idx = next(ctc_value_idx)
            consensus_labels = [_choose_between_consensus_dicts(idx, consensus_maps) for idx in pair]
            fragment_idxs = [in_what_fragment(idx, fragments_as_residue_idxs) for idx in pair]
            site_as_gc[key].append(ContactPair(pair,
                                               [itraj[:, idx] for itraj in ctcs],
                                               time_array,
                                               top=refgeom.top,
                                               consensus_labels=consensus_labels,
                                               trajs=xtcs,
                                               fragment_idxs=fragment_idxs,
                                               fragment_names=[fragment_names[idx] for idx in fragment_idxs],
                                               atom_pair_trajs=[itraj[:, [idx * 2, idx * 2 + 1]] for itraj in
                                                                at_pair_trajs]

                                               #colors=[fragcolors[idx] for idx in idxs]
                                               ))
        site_as_gc[key] = ContactGroup(site_as_gc[key])

    print("The following files have been created")
    panelheight = 3
    n_cols = _np.min((4, len(sites)))
    n_rows = _np.ceil(len(sites) / n_cols).astype(int)
    panelsize = 4
    panelsize2font = 3.5
    histofig, histoax = plt.subplots(n_rows, n_cols, sharex=True, sharey=True,
                                     figsize=(n_cols * panelsize * 2, n_rows * panelsize), squeeze=False)

    # One loop for the histograms
    _rcParams["font.size"] = panelsize * panelsize2font
    for jax, (site_name, isite_nh) in zip(histoax.flatten(),
                                       site_as_gc.items()):
        isite_nh.plot_freqs_as_bars(ctc_cutoff_Ang, site_name,
                                    jax=jax,
                                    xlim=_np.max([ss["n_bonds"] for ss in sites]),
                                    label_fontsize_factor=panelsize2font / panelsize,
                                    shorten_AAs=short_AA_names
                                    )


    if scheme!="closest-heavy":
        scheme_desc='%s.'%scheme
    else:
        scheme_desc=''
    histofig.tight_layout(h_pad=2, w_pad=0, pad=0)
    fname = "%s.overall.%s%s" % (output_desc, scheme_desc, graphic_ext.strip("."))
    fname = _path.join(output_dir, fname)
    histofig.savefig(fname, dpi=graphic_dpi)
    plt.close(histofig)
    print("The following files have been created")
    print(fname)
    for site_name, isite_nh in site_as_gc.items():
        fname_no_time = '%s.%s@%2.1f_Ang.%s' % (output_desc,
                                        site_name.strip().replace(" ","_"),
                                        ctc_cutoff_Ang,
                                        table_ext)
        fname_no_time = _path.join(output_dir, fname_no_time)


        fname = '%s.%s.time_trace@%2.1f_Ang.%s' % (output_desc,
                                        site_name.strip().replace(" ","_"),
                                        ctc_cutoff_Ang,
                                        graphic_ext)
        fname = _path.join(output_dir,fname)
        myfig = isite_nh.plot_timedep_ctcs(panelheight,
                                           color_scheme=_my_color_schemes(curve_color),
                                           ctc_cutoff_Ang=ctc_cutoff_Ang,
                                           n_smooth_hw=n_smooth_hw,
                                           dt=_tunit2tunit["ps"][t_unit],
                                           t_unit=t_unit,
                                           gray_background=gray_background,
                                           shorten_AAs=short_AA_names,
                                           plot_N_ctcs=True,
                                           ylim_Ang=ylim_Ang,
                                           )[0]
        # One title for all axes on top
        myfig.axes[0].set_title("site: %s" % (isite["name"]))
        plt.savefig(fname, bbox_inches="tight", dpi=graphic_dpi)
        plt.close(myfig)
        print(fname)
        if table_ext is not None:
            if table_ext == 'xlsx':
                isite_nh.frequency_spreadsheet(ctc_cutoff_Ang, fname_no_time,
                                            write_interface=False,
                                            by_atomtypes=True,
                                            # AA_format="long",
                                            split_label="join"
                                            )
            else:
                with open(fname_no_time, 'w') as f:
                    f.write(isite_nh.frequency_str_ASCII_file(ctc_cutoff_Ang))
            print(fname_no_time)

    return

def neighborhood_comparison(*args, **kwargs):
    return _compare_groups_of_contacts(*args, **kwargs)